---
author: "Brandon Cruz"
title: "AWS Outage & What It Teaches Us About Business Continuity"
date: "2025-10-21T00:00:00+00:00"
tags:
  - AWS
  - Business Continuity Plans
categories: ["blog"]
series:
---

Yesterdayâ€™s (10/20/25) AWS outage got a lot of folks thinking. We all knew this could happen â€” yet somehow, everyone was still surprised when it did.

What stood out most to me was how quickly the conversations shifted to â€œspin up a new region,â€ even though for most teams, that process takes longer than just waiting out the outage. Isnâ€™t that exactly what Business Continuity Plans (BCPs) are supposed to account for?

A business continuity plan isnâ€™t for when something you rely on is down for a day. Itâ€™s for when a service you depend on is retiring tomorrow â€” or when the entirety of us-east-1 is literally on fire and unrecoverable. Thatâ€™s a powerful distinction. BCPs arenâ€™t meant to solve every minor disruption. Theyâ€™re about survivability â€” what happens when the infrastructure you depend on becomes permanently unavailable.

At the same time, these â€œshort outagesâ€ arenâ€™t exactly rare. We treat them as edge cases, but they happen often enough to expose how few organizations are truly prepared for a catastrophic failure.

Many of us engineers know all too well: If your service must stay up through a region failure, you have to design for that â€” multi-region failover, hot spares, regular drills. But that reliability comes with exponentially higher cost. The trade-off isnâ€™t always worth it versus a single day of downtime.

Ultimately, itâ€™s a reminder that resilience isnâ€™t binary. You have to decide what level of reliability your business truly needs â€” and what level of complexity and spend youâ€™re willing to accept to get there.

And thatâ€™s where the heart of the matter lies â€” risk management.

What is the probability that your infrastructure will fail, and what will the impact be when it does? You can implement controls to limit that risk â€” auto-failover to another region, multi-cloud redundancy, or automated recovery mechanisms â€” but each layer of protection increases complexity and cost.

Achieving more â€œninesâ€ of availability means exponential investment. Even the big three hyperscalers fail from time to time, despite their deep pockets. Fully mitigating all risk is impossible â€” the real challenge is finding the right balance between residual risk and the additional cost required to reduce it.

ğŸ’¡ Takeaway:
Control what you can control. Design and build for graceful degradation, use queues and backoff strategies, automate recovery. Donâ€™t chase zero downtime â€” aim for predictable recovery and operational resilience.
